{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder Setting (Just the first time you are preparing the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET YOUR WORKING DIRECTORY (WHERE DIFFUSION MODEL IS INSTALLED AND WHERE TESTS WILL GO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\SMC_WORK_DIRECTORY\\e_diffusionModelWrapped\n"
     ]
    }
   ],
   "source": [
    "nameOfDirectory=\"C:/Users/user/Documents/SMC_WORK_DIRECTORY/e_diffusionModelWrapped/\"\n",
    "%cd {nameOfDirectory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTICE THAT IN THAT DIRECTORY APART FROM THE DIFFUSION MODEL FILES, THERE SHOULD BE THE FOLLOWING FOLDERS: \n",
    "\n",
    "-Data -Results -exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 Results이(가) 이미 있습니다.\n",
      "하위 디렉터리 또는 파일 Data이(가) 이미 있습니다.\n",
      "하위 디렉터리 또는 파일 exp이(가) 이미 있습니다.\n"
     ]
    }
   ],
   "source": [
    "!mkdir Results\n",
    "!mkdir Data\n",
    "!mkdir exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW ITS TIME TO CREATE A NAME FOR YOUR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfDataset=\"emergency_smc2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\SMC_WORK_DIRECTORY\\e_diffusionModelWrapped\\Data\n",
      "C:\\Users\\user\\Documents\\SMC_WORK_DIRECTORY\\e_diffusionModelWrapped\n",
      "C:\\Users\\user\\Documents\\SMC_WORK_DIRECTORY\\e_diffusionModelWrapped\\exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 emergency_smc2이(가) 이미 있습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\SMC_WORK_DIRECTORY\\e_diffusionModelWrapped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 emergency_smc2이(가) 이미 있습니다.\n"
     ]
    }
   ],
   "source": [
    "%cd Data\n",
    "!mkdir {nameOfDataset}\n",
    "%cd ..\n",
    "%cd exp\n",
    "!mkdir {nameOfDataset}\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW YOU SHOULD ADD YOUR CSV FILE INTO THE FOLDER YOU CREATED UNDER DATA/nameOfDataset BEING nameOfDataset THE ONE YOU JUST GAVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIVE A NAME TO THE ACTUAL TEST (ANY NAME WILL WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfTest=\"firstTest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMPLY RUN THIS, IT WILL CREATE A RESULTS FOLDER WITH THE PREVIOUSLY GIVEN NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\SMC_WORK_DIRECTORY\\e_diffusionModelWrapped\\Results\n",
      "C:\\Users\\user\\Documents\\SMC_WORK_DIRECTORY\\e_diffusionModelWrapped\\Results\\firstTest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 firstTest이(가) 이미 있습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\SMC_WORK_DIRECTORY\\e_diffusionModelWrapped\\Results\n",
      "C:\\Users\\user\\Documents\\SMC_WORK_DIRECTORY\\e_diffusionModelWrapped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 Real이(가) 이미 있습니다.\n"
     ]
    }
   ],
   "source": [
    "%cd Results\n",
    "!mkdir {nameOfTest}\n",
    "%cd {nameOfTest}\n",
    "!mkdir Real\n",
    "%cd ..\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation For Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD HERE YOUR OWN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HR</th>\n",
       "      <th>DBP</th>\n",
       "      <th>RR</th>\n",
       "      <th>SBP</th>\n",
       "      <th>SPO2</th>\n",
       "      <th>count_ER</th>\n",
       "      <th>count_ICU</th>\n",
       "      <th>count_Surgery</th>\n",
       "      <th>...</th>\n",
       "      <th>pud</th>\n",
       "      <th>dm_woc</th>\n",
       "      <th>dm_c</th>\n",
       "      <th>hemi</th>\n",
       "      <th>renal</th>\n",
       "      <th>tu_le</th>\n",
       "      <th>mst</th>\n",
       "      <th>mld</th>\n",
       "      <th>sld</th>\n",
       "      <th>dth_In</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112347</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112348</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112349</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112350</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112351</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112352 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE  GENDER     HR    DBP    RR    SBP  SPO2  count_ER  count_ICU  \\\n",
       "0        62       0   74.0   80.0  20.0  121.0  98.0       0.0        0.0   \n",
       "1        55       1   96.0   82.0  20.0  161.0  96.0       2.0        0.0   \n",
       "2        75       0  108.0   50.0  15.0   92.0  98.0       0.0        0.0   \n",
       "3        59       1  109.0   75.0  18.0  120.0  99.0       0.0        0.0   \n",
       "4        42       1   91.0   60.0  20.0  100.0  98.0       0.0        0.0   \n",
       "...     ...     ...    ...    ...   ...    ...   ...       ...        ...   \n",
       "112347   68       0   96.0   75.0  20.0  125.0  95.0       0.0        0.0   \n",
       "112348   67       0   87.0  105.0  20.0  146.0  99.0       0.0        0.0   \n",
       "112349   80       1   72.0   87.0  16.0  151.0  97.0       0.0        0.0   \n",
       "112350   53       0   78.0  103.0  20.0  132.0  97.0       0.0        0.0   \n",
       "112351   54       0   93.0  111.0  20.0  177.0  97.0       0.0        1.0   \n",
       "\n",
       "        count_Surgery  ...  pud  dm_woc  dm_c  hemi  renal  tu_le  mst  mld  \\\n",
       "0                 0.0  ...  0.0     0.0   0.0   0.0    0.0    1.0  0.0  1.0   \n",
       "1                 0.0  ...  0.0     0.0   0.0   0.0    0.0    1.0  0.0  1.0   \n",
       "2                 0.0  ...  0.0     0.0   0.0   0.0    0.0    1.0  0.0  1.0   \n",
       "3                 1.0  ...  0.0     0.0   0.0   0.0    0.0    0.0  0.0  0.0   \n",
       "4                 0.0  ...  0.0     0.0   0.0   0.0    0.0    0.0  0.0  0.0   \n",
       "...               ...  ...  ...     ...   ...   ...    ...    ...  ...  ...   \n",
       "112347            0.0  ...  0.0     0.0   0.0   0.0    0.0    1.0  0.0  0.0   \n",
       "112348            0.0  ...  0.0     0.0   0.0   0.0    0.0    0.0  0.0  0.0   \n",
       "112349            0.0  ...  0.0     0.0   0.0   0.0    0.0    0.0  0.0  0.0   \n",
       "112350            0.0  ...  0.0     1.0   1.0   0.0    1.0    0.0  0.0  0.0   \n",
       "112351            0.0  ...  0.0     1.0   1.0   0.0    1.0    0.0  0.0  1.0   \n",
       "\n",
       "        sld  dth_In  \n",
       "0       0.0     0.0  \n",
       "1       0.0     1.0  \n",
       "2       0.0     0.0  \n",
       "3       0.0     0.0  \n",
       "4       0.0     0.0  \n",
       "...     ...     ...  \n",
       "112347  0.0     0.0  \n",
       "112348  0.0     0.0  \n",
       "112349  0.0     0.0  \n",
       "112350  0.0     0.0  \n",
       "112351  0.0     0.0  \n",
       "\n",
       "[112352 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"Data/emergency_smc/cleanedDataWithoutOutliers_SPO2Corrected_clean.csv\", sep=\",\", encoding='cp1252')\n",
    "#You can shuffle the data if you whish by running the line below\n",
    "#data = data.sample(frac=1).reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEPARATE RANDOMLY ON THREE SPLITS (TRAINING, VALIDATION AND TEST SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#train_percent states the percentage of your dataset that will belong to the training set\n",
    "#validate_percent states the percentage of your dataset that will belong to the validation set\n",
    "#the remaining percentage will go to the test set\n",
    "\n",
    "#you can change the seed to make results vary\n",
    "#notice that if you want to replicate the whole dataset you may want a huge \n",
    "#training set and very small validation and test set\n",
    "#for instance: train_percent=0.99, validate_percent=0.001\n",
    "def train_validate_test_split(df, train_percent=0.99, validate_percent=0.001, seed=1):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test\n",
    "\n",
    "trainingSet, ValidationSet, testSet = train_validate_test_split(data,seed=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARSE TO NUYMPY EACH SPLIT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TabDDPM does not process directly an excel file but loads numpy files. We will create the corresponding numpy files and locate them on our data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandasDataFrameToNumpy(nameOfDataset, nameOfTest, trainingSet, ValidationSet, testSet):\n",
    "    \n",
    "    ##Training Set To Numpy in folder \"Results\\nameOfTest\\Real\\\"\n",
    "    labels= trainingSet.drop(trainingSet.columns[0:26],axis = 1)\n",
    "    trainingData = trainingSet.drop(trainingSet.columns[-1],axis = 1)\n",
    "    trainingData = trainingData.to_numpy(dtype='float32')\n",
    "    labels = np.array(labels['dth_In'].values).astype(np.int64)\n",
    "    \n",
    "    with open('Data\\\\'+nameOfDataset+'\\X_num_train.npy', 'wb') as f:\n",
    "        np.save(f, trainingData)\n",
    "    with open('Data\\\\'+nameOfDataset+'\\y_train.npy', 'wb') as f:\n",
    "        np.save(f, labels)\n",
    "    \n",
    "    with open(\"Results\\\\\"+nameOfTest+\"\\Real\\X_num_train.npy\", 'wb') as f:\n",
    "        np.save(f, trainingData)\n",
    "    with open(\"Results\\\\\"+nameOfTest+\"\\Real\\y_train.npy\", 'wb') as f:\n",
    "        np.save(f, labels)\n",
    "        \n",
    "    \n",
    "    ##Validation Set To Numpy in folder \"Results\\nameOfTest\\Real\\\"\n",
    "    labels= ValidationSet.drop(ValidationSet.columns[0:26],axis = 1)\n",
    "    validationData = ValidationSet.drop(ValidationSet.columns[-1],axis = 1)\n",
    "    validationData = validationData.to_numpy(dtype='float32')\n",
    "    labels = np.array(labels['dth_In'].values).astype(np.int64)\n",
    "    \n",
    "    with open('Data\\\\'+nameOfDataset+'\\X_num_val.npy', 'wb') as f:\n",
    "        np.save(f, validationData)\n",
    "    with open('Data\\\\'+nameOfDataset+'\\y_val.npy', 'wb') as f:\n",
    "        np.save(f, labels)\n",
    "        \n",
    "    with open(\"Results\\\\\"+nameOfTest+\"\\Real\\X_num_val.npy\", 'wb') as f:\n",
    "        np.save(f, validationData)\n",
    "    with open(\"Results\\\\\"+nameOfTest+\"\\Real\\y_val.npy\", 'wb') as f:\n",
    "        np.save(f, labels)\n",
    "    \n",
    "    ##Test Set To Numpy in folder \"Results\\nameOfTest\\Real\\\"\n",
    "    labels= testSet.drop(testSet.columns[0:26],axis = 1)\n",
    "    testData = testSet.drop(testSet.columns[-1],axis = 1)\n",
    "    testData = testData.to_numpy(dtype='float32')\n",
    "    labels = np.array(labels['dth_In'].values).astype(np.int64)\n",
    "    \n",
    "    with open('Data\\\\'+nameOfDataset+'\\X_num_test.npy', 'wb') as f:\n",
    "        np.save(f, testData)\n",
    "    with open('Data\\\\'+nameOfDataset+'\\y_test.npy', 'wb') as f:\n",
    "        np.save(f, labels)\n",
    "        \n",
    "    with open(\"Results\\\\\"+nameOfTest+\"\\Real\\X_num_test.npy\", 'wb') as f:\n",
    "        np.save(f, testData)\n",
    "    with open(\"Results\\\\\"+nameOfTest+\"\\Real\\y_test.npy\", 'wb') as f:\n",
    "        np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasDataFrameToNumpy(nameOfDataset, nameOfTest, trainingSet, ValidationSet, testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVEN THOUGH TRAINING COULD BE DONE IN A JUPYTER NOTEBOOK IF PYTHON PATHs ARE NOT CORRECTLY INSTALLED IT IS LIKELY TO GIVE ERRORS, THEREFORE THE MOST STRAIGHTFORWARD WAY OF DOING THE TRAINING IS THE FOLLOWING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a anaconda prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the right folder with the first command on this notebook, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:/Users/user/Documents/SMC_WORK_DIRECTORY/e_diffusionModelWrapped/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then activate your environment where you have installed all the TabDDPM dependencies (if you didn't follow the tutorial on the github readme to install the necessary dependencies and GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate nameofyourenvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO TRAIN THE MODEL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the root folder, there is a file called config.toml, that is the current training configuration. Change it at your will and it is important that you make sure the paths are correct inside. Finally copy that file into your exp/nameOfDataset/ folder. Also there is another file called info.json in the root folder that should be copied to Data/nameOfDataset/ and after modifying it at your will you will be able to train the model as follows (in a conda prompt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/pipeline.py --config exp/nameOfDataset/config.toml --train --sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO FINETUNE THE MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Training: Extracting New Dataset To Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IN ORDER TO COPY DATA TO OUR EXPERIMET FOLDER WE DO THE FOLLOWING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/user/Documents/SMC_WORK_DIRECTORY/e_diffusionModelWrapped//Results/emergency_smc2/Synthetic/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    " \n",
    "# path to source directory\n",
    "#src_dir = 'C:/Users/user/Documents/SMC_WORK_DIRECTORY/b_SytheticData_Project/exp/emergency_smc/results/'\n",
    "src_dir = nameOfDirectory+'/exp/'+nameOfDataset+'/results/'\n",
    "\n",
    " \n",
    "# path to destination directory\n",
    "dest_dir = nameOfDirectory+'/Results/'+nameOfDataset+'/Synthetic/'\n",
    "\n",
    " \n",
    "# getting all the files in the source directory\n",
    "files = os.listdir(src_dir)\n",
    " \n",
    "shutil.copytree(src_dir, dest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING ORIGINAL AND SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "trainData = np.load(nameOfDirectory+'/data/'+nameOfDataset+'/X_num_train.npy',allow_pickle=True)\n",
    "trainDataLabel = np.load(nameOfDirectory+'/data/'+nameOfDataset+'/y_train.npy',allow_pickle=True)\n",
    "trainDataSynthetic = np.load(nameOfDirectory+'/exp/'+nameOfDataset+'/results/X_num_train.npy',allow_pickle=True)\n",
    "trainDataLabelSynthetic = np.load(nameOfDirectory+'/exp/'+nameOfDataset+'/results/y_train.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE YOU SHOULD CHANGE THE COLUMNS NAMES TO YOUR ACTUAL COLUMNS NAMES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, to get easily the column names you can use the following: **list(data.columns)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we extract the data into a pandas dataframe with the given column names and the second pandas dataframe is the outcome variable if there is\n",
    "trainDataPd = pd.DataFrame(trainData, columns = ['AGE','GENDER','HR','DBP','RR','SBP','SPO2','count_ER','count_ICU','count_Surgery','MI','CHF','PVD','str','dem','cpd','rd','pud','dm_woc','dm_c','hemi','renal','tu_le','mst','mld','sld'])\n",
    "trainDataLabelPd = pd.DataFrame(trainDataLabel, columns = ['dth_In'])\n",
    "\n",
    "#Here we extract the data into a pandas dataframe with the given column names and the second pandas dataframe is the outcome variable if there is\n",
    "trainDataSyntheticPd = pd.DataFrame(trainDataSynthetic, columns = ['AGE','GENDER','HR','DBP','RR','SBP','SPO2','count_ER','count_ICU','count_Surgery','MI','CHF','PVD','str','dem','cpd','rd','pud','dm_woc','dm_c','hemi','renal','tu_le','mst','mld','sld'])\n",
    "trainDataLabelSyntheticPd = pd.DataFrame(trainDataLabelSynthetic, columns = ['dth_In'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataPd = pd.concat([trainDataPd, trainDataLabelPd ], axis=1)\n",
    "trainDataSyntheticPd = pd.concat([trainDataSyntheticPd, trainDataLabelSyntheticPd], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINALLY RESULTS GET EXTRACTED ONTO A CSV FILE IN OUR RESULTS DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataPd.to_csv(\"Results/\"+nameOfTest+\"/RealTDDPM_1.csv\") \n",
    "trainDataSyntheticPd.to_csv(\"Results/\"+nameOfTest+\"/SyntheticTDDPM_1.csv\") \n",
    "testSet.to_csv(\"Results/\"+nameOfTest+\"/testTDDPM_1.csv\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabDDPM",
   "language": "python",
   "name": "tabddpm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a06af253165e97d0c1e75e8bf6d3252013856f30b8177e11b02d3fa36c37333d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
